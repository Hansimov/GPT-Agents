from datetime import datetime
import json
import logging
import os
from pathlib import Path

# python -m pip install --upgrade openai
import openai

# python -m pip install git+https://github.com/dsdanielpark/Bard-API.git
import bardapi
from bardapi import Bard

# python -m pip install poe-api
import poe
poe.logger.setLevel(logging.INFO)


def init_os_envs():
    with open(Path(__file__).parent / "secrets.json", "r") as rf:
        secrets = json.load(rf)

    for proxy_env in ["http_proxy", "https_proxy"]:
        os.environ[proxy_env] = secrets["http_proxy"]

    os.environ["OPENAI_API_KEY"] = secrets["openai_api_key"]
    os.environ["BARD_API_KEY"] = secrets["bard_api_key"]
    os.environ["CLAUDE_API_KEY"] = secrets["claude_api_key"]


init_os_envs()
openai.api_key = os.environ["OPENAI_API_KEY"]


"""
* openai-cookbook: How to format inputs to ChatGPT models
  * https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb

  
# API Request

A chat API call has two required inputs:
1. `model`: The name of the model you want to use
  * Example: "text-davinci-003", "gpt-3.5-turbo", "gpt-4"
  * https://platform.openai.com/docs/models/gpt-3-5
2. `messages`: A list of message objects, where each object has two required fields:
  * `role`: Role of the messenger
    * Choices: "system", "user", "assistant"
  * `content`: Content of the message
    * Example: "Write me a beautiful poem"

Messages can also contain an optional `name` field, which give the messenger a name.
* Example: "example-user", "Alice", "BlackbeardBot".
> Names may not contain spaces.

Typically, a conversation will:
1. start with a `system` message that tells the assistant how to behave
2. followed by alternating `user` and `assistant` messages
> You are not required to follow this format.


# API Response

The response object has a few fields:

1. `id`: ID of the request
2. `object`: Type of object returned
  * Example: `chat.completion`
3. `created`: Timestamp of the request
4. `model`: Full name of the model used to generate the response
5. `usage`: Number of tokens used to generate the replies, counting prompt, completion, and total
6. `choices`: a list of completion objects (only one, unless you set n greater than 1)
  * `message`: Message object generated by the model, with role and content
  * `finish_reason`: Reason for the model stopped generating text (either stop, or length if max_tokens limit was reached)
  * `index`: Index of the completion in the list of choices

# Tips
System messages
* The system message can be used to prime the assistant with different personalities or behaviors.
* Be aware that gpt-3.5-turbo-0301 does not generally pay as much attention to the system message as gpt-4-0314.
* Therefore, for "gpt-3.5-turbo-0301", we recommend PLACING IMPORTANT INSTRUCTIONS IN THE `USER` MESSAGE INSTEAD.
* Some developers have found success in continually moving the system message near the end of the conversation to keep the model's attention from drifting away as conversations get longer.


"""


class ChatGPTAgent:
    def __init__(
        self,
        original_text,
        model="gpt-3.5-turbo",
        task="en2zh",
    ):
        task_system_message_dict = {
            "en2zh": "你是一个英译中翻译专家。你的任务是将给定的英文如实翻译成中文。",
        }
        self.model = model
        self.system_message = task_system_message_dict[task]
        self.original_text = original_text

    def run(self):
        response = openai.ChatCompletion.create(
            model=self.model,
            messages=[
                {
                    "role": "user",
                    "content": self.system_message + self.original_text,
                },
            ],
            temperature=0,
        )

        self.translated_text = response["choices"][0]["message"]["content"]
        return self.translated_text


class BardAgent:
    def __init__(self):
        pass

    def run(self):
        question = "Today's Weather of Shanghai Minhang. For temperature, you should Celsius Degree instead of Fahrenheit. You should output the statistics in table format."
        # answer = Bard().get_answer(question)["content"]
        # print(answer)
        bard_session = bardapi.core.Bard(token=os.environ["BARD_API_KEY"])
        response = bard_session.get_answer(question)
        answer = response["content"]
        print(answer)


class ClaudeAgent:
    def __init__(self):
        pass

    def run(self):
        claude_client = poe.Client(os.environ["CLAUDE_API_KEY"], pro)
        print(json.dumps(claude_client.bot_names, indent=2))
        # message = "Summarize the GNU GPL v3"
        # for chunk in claude_client.send_message("capybara", message, with_chat_break=True):
        #     print(chunk["text_new"], end="", flush=True)
        # print()


if __name__ == "__main__":
    translater = ChatGPTAgent(
        "Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery"
    )
    translater.run()
    print(translater.translated_text)
